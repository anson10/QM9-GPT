{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7ba8cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anson/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4c61629",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed/qm9_clean.csv')\n",
    "smiles_list = df['smiles'].astype('str').tolist()\n",
    "gap_values = df['gap_ev'].values\n",
    "\n",
    "# Create Vocabulary\n",
    "chars = sorted(list(set(''.join(smiles_list))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "smiles_vocab_size = len(itos)\n",
    "\n",
    "# Binning the HOMO-LUMO Gap (eV) into 50 discrete tokens\n",
    "num_buckets = 50\n",
    "gap_min, gap_max = gap_values.min(), gap_values.max()\n",
    "gap_buckets = ((gap_values - gap_min) / (gap_max - gap_min) * (num_buckets - 1)).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00ab83a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total_vocab_size = smiles_vocab_size + num_buckets\n",
    "block_size = 24\n",
    "\n",
    "def build_conditioned_dataset(smiles, buckets):\n",
    "    X, Y = [], []\n",
    "    for s, b in zip(smiles, buckets):\n",
    "        # Prepend the property token (target) to the sequence context\n",
    "        target_token = smiles_vocab_size + b \n",
    "        context = [target_token] + [0] * (block_size - 1)\n",
    "        for ch in s + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix]\n",
    "    return torch.tensor(X), torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8aeaa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split and Build\n",
    "n1 = int(0.8 * len(smiles_list))\n",
    "Xtr, Ytr = build_conditioned_dataset(smiles_list[:n1], gap_buckets[:n1])\n",
    "Xdev, Ydev = build_conditioned_dataset(smiles_list[n1:], gap_buckets[n1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51d847a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, fan_in, fan_out, bias=True):\n",
    "        self.weight = torch.randn((fan_in, fan_out)) / fan_in**0.5\n",
    "        self.bias = torch.zeros(fan_out) if bias else None\n",
    "    def __call__(self, x):\n",
    "        self.out = x @ self.weight\n",
    "        if self.bias is not None: self.out += self.bias\n",
    "        return self.out\n",
    "    def parameters(self):\n",
    "        return [self.weight] + ([] if self.bias is None else [self.bias])\n",
    "\n",
    "class BatchNorm1d:\n",
    "    def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "        self.eps, self.momentum, self.training = eps, momentum, True\n",
    "        self.gamma, self.beta = torch.ones(dim), torch.zeros(dim)\n",
    "        self.running_mean, self.running_var = torch.zeros(dim), torch.ones(dim)\n",
    "    def __call__(self, x):\n",
    "        if self.training:\n",
    "            dim = (0, 1) if x.ndim == 3 else 0\n",
    "            xmean = x.mean(dim, keepdim=True)\n",
    "            xvar = x.var(dim, keepdim=True)\n",
    "        else:\n",
    "            xmean, xvar = self.running_mean, self.running_var\n",
    "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps)\n",
    "        self.out = self.gamma * xhat + self.beta\n",
    "        if self.training:\n",
    "            with torch.no_grad():\n",
    "                self.running_mean = (1-self.momentum)*self.running_mean + self.momentum*xmean\n",
    "                self.running_var = (1-self.momentum)*self.running_var + self.momentum*xvar\n",
    "        return self.out\n",
    "    def parameters(self):\n",
    "        return [self.gamma, self.beta]\n",
    "\n",
    "class Tanh:\n",
    "    def __call__(self, x):\n",
    "        self.out = torch.tanh(x)\n",
    "        return self.out\n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "class Embedding:\n",
    "    def __init__(self, num_embeddings, embedding_dim):\n",
    "        self.weight = torch.randn((num_embeddings, embedding_dim))\n",
    "    def __call__(self, IX):\n",
    "        self.out = self.weight[IX]\n",
    "        return self.out\n",
    "    def parameters(self):\n",
    "        return [self.weight]\n",
    "\n",
    "class FlattenConsecutive:\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "    def __call__(self, x):\n",
    "        B, T, C = x.shape\n",
    "        x = x.view(B, T // self.n, C * self.n)\n",
    "        if x.shape[1] == 1: x = x.squeeze(1)\n",
    "        self.out = x\n",
    "        return self.out\n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "class Sequential:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers: x = layer(x)\n",
    "        self.out = x\n",
    "        return self.out\n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb1a6fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embd = 24\n",
    "n_hidden = 512\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(total_vocab_size, n_embd),\n",
    "    FlattenConsecutive(2), Linear(n_embd * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    FlattenConsecutive(2), Linear(n_hidden * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    FlattenConsecutive(2), Linear(n_hidden * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    Linear(n_hidden, smiles_vocab_size), # Predicting only SMILES characters\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a5a8a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = model.parameters()\n",
    "for p in parameters: p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "318ab686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 150000: loss 3.2872\n",
      "  10000/ 150000: loss 0.8303\n",
      "  20000/ 150000: loss 1.4544\n",
      "  30000/ 150000: loss 0.7955\n",
      "  40000/ 150000: loss 0.9836\n",
      "  50000/ 150000: loss 1.0029\n",
      "  60000/ 150000: loss 0.9225\n",
      "  70000/ 150000: loss 0.7557\n",
      "  80000/ 150000: loss 0.6870\n",
      "  90000/ 150000: loss 0.9287\n",
      " 100000/ 150000: loss 0.8494\n",
      " 110000/ 150000: loss 0.9757\n",
      " 120000/ 150000: loss 1.0272\n",
      " 130000/ 150000: loss 0.9355\n",
      " 140000/ 150000: loss 0.8669\n"
     ]
    }
   ],
   "source": [
    "max_steps = 150000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix]\n",
    "    \n",
    "    logits = model(Xb)\n",
    "    if logits.ndim == 3: logits = logits[:, -1, :]\n",
    "    loss = F.cross_entropy(logits, Yb)\n",
    "    \n",
    "    for p in parameters: p.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    lr = 0.1 if i < 100000 else 0.01\n",
    "    for p in parameters: p.data += -lr * p.grad\n",
    "    \n",
    "    if i % 10000 == 0:\n",
    "        print(f'{i:7d}/{max_steps:7d}: loss {loss.item():.4f}')\n",
    "    lossi.append(loss.log10().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60a98d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_for_property(target_ev):\n",
    "    for layer in model.layers:\n",
    "        if hasattr(layer, 'training'): layer.training = False\n",
    "    \n",
    "    # Map target eV to specific bucket token\n",
    "    b = int(((target_ev - gap_min) / (gap_max - gap_min) * (num_buckets - 1)))\n",
    "    b = max(0, min(num_buckets - 1, b))\n",
    "    condition_token = smiles_vocab_size + b\n",
    "    \n",
    "    context = [condition_token] + [0] * (block_size - 1)\n",
    "    out = []\n",
    "    while True:\n",
    "        logits = model(torch.tensor([context]))\n",
    "        if logits.ndim == 3: logits = logits[:, -1, :]\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        ix = torch.multinomial(probs, num_samples=1).item()\n",
    "        context = context[1:] + [ix]\n",
    "        if ix == 0: break\n",
    "        out.append(itos[ix])\n",
    "    return \"\".join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1d08785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating molecule for target: 7.0 eV\n",
      "CC12COC3CC2C13\n"
     ]
    }
   ],
   "source": [
    "target_gap = 7.0 \n",
    "print(f\"Generating molecule for target: {target_gap} eV\")\n",
    "print(generate_for_property(target_gap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10940c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictor model successfully loaded in Task 3 notebook.\n"
     ]
    }
   ],
   "source": [
    "# 1. Define the Regression Model Architecture (from Task 2)\n",
    "# It must have the exact same structure: Linear(n_hidden, 1) at the end\n",
    "predictor_model = Sequential([\n",
    "    Embedding(total_vocab_size, n_embd),\n",
    "    FlattenConsecutive(2), Linear(n_embd * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    FlattenConsecutive(2), Linear(n_hidden * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    FlattenConsecutive(2), Linear(n_hidden * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    FlattenConsecutive(2), Linear(n_hidden * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    FlattenConsecutive(2), Linear(n_hidden * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    Linear(n_hidden, 1), \n",
    "])\n",
    "\n",
    "saved_params = torch.load('predictor_weights.pt')\n",
    "for p, p_saved in zip(predictor_model.parameters(), saved_params):\n",
    "    p.data = p_saved.data\n",
    "    p.requires_grad = False # Freeze weights so they don't change during gen tests\n",
    "\n",
    "print(\"Predictor model successfully loaded in Task 3 notebook.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44c97c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 2.0 eV\n",
      "Generated: CC1C2COCCCC2O1\n",
      "Predictor says: 7.3022 eV\n",
      "Accuracy Error: 5.3022 eV\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def validate_inverse_design(target_ev):\n",
    "    # 1. Generate the molecule using the Conditioned Generator (model)\n",
    "    gen_smiles = generate_for_property(target_ev)\n",
    "    \n",
    "    # 2. Prepare the SMILES for the Predictor\n",
    "    encoded = [stoi.get(ch, 0) for ch in gen_smiles[:32]]\n",
    "    padded = encoded + [0] * (32 - len(encoded))\n",
    "    input_tensor = torch.tensor([padded])\n",
    "    \n",
    "    # 3. Predict using the loaded Predictor model\n",
    "    for layer in predictor_model.layers:\n",
    "        if hasattr(layer, 'training'): layer.training = False\n",
    "    \n",
    "    pred_ev = predictor_model(input_tensor).item()\n",
    "    \n",
    "    print(f\"Target: {target_ev} eV\")\n",
    "    print(f\"Generated: {gen_smiles}\")\n",
    "    print(f\"Predictor says: {pred_ev:.4f} eV\")\n",
    "    print(f\"Accuracy Error: {abs(target_ev - pred_ev):.4f} eV\")\n",
    "\n",
    "# RUN THE TEST\n",
    "validate_inverse_design(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "374351ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Molecule N=C1ON=C(N)C#N is NEW (Discovery!).\n"
     ]
    }
   ],
   "source": [
    "# Create a set of all training molecules for fast lookup\n",
    "training_set = set(df['smiles'].tolist())\n",
    "\n",
    "# Check your generated molecule\n",
    "if generated_smiles in training_set:\n",
    "    print(f\"Molecule {generated_smiles} was found in the training data (Memorization).\")\n",
    "else:\n",
    "    print(f\"Molecule {generated_smiles} is NEW (Discovery!).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e182e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting batch generation for 7.0 eV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[04:06:16] SMILES Parse Error: unclosed ring for input: 'NC(=N)C1=O'\n",
      "[04:06:16] SMILES Parse Error: unclosed ring for input: 'CCC1CC(C)C(C)(C)CO'\n",
      "[04:06:16] SMILES Parse Error: unclosed ring for input: 'CC(C#C)C1C'\n",
      "[04:06:17] SMILES Parse Error: unclosed ring for input: 'NCC1C=C(OC=O)C=O'\n",
      "[04:06:17] Explicit valence for atom # 4 C, 5, is greater than permitted\n",
      "[04:06:17] SMILES Parse Error: unclosed ring for input: 'CC1(O)C(C)OC=O'\n",
      "[04:06:17] SMILES Parse Error: unclosed ring for input: 'O=CC1CC1CN1'\n",
      "[04:06:17] Explicit valence for atom # 7 C, 5, is greater than permitted\n",
      "[04:06:17] SMILES Parse Error: syntax error while parsing: NC(C[NH2+]2)C[N\n",
      "[04:06:17] SMILES Parse Error: check for mistakes around position 15:\n",
      "[04:06:17] NC(C[NH2+]2)C[N\n",
      "[04:06:17] ~~~~~~~~~~~~~~^\n",
      "[04:06:17] SMILES Parse Error: Failed parsing SMILES 'NC(C[NH2+]2)C[N' for input: 'NC(C[NH2+]2)C[N'\n",
      "[04:06:17] SMILES Parse Error: unclosed ring for input: 'CNC1C(O)CN#C'\n",
      "[04:06:17] SMILES Parse Error: unclosed ring for input: 'CNC1=C(O)C(C)C(C)(O)C#N'\n",
      "[04:06:17] SMILES Parse Error: unclosed ring for input: 'CC1=C2CC3(C1)CC2'\n",
      "[04:06:17] SMILES Parse Error: ring closure 1 duplicates bond between atom 6 and atom 7 for input: 'N=COC(C#C)C1C1CC2(CC2)C=C1'\n",
      "[04:06:17] SMILES Parse Error: unclosed ring for input: 'CC(=O)NCC(=O)C1(N)C#N'\n",
      "[04:06:17] SMILES Parse Error: unclosed ring for input: 'CNC1=C(O)NC=O'\n",
      "[04:06:17] SMILES Parse Error: extra open parentheses while parsing: CC1C2C(CC(=O)C1=NC=CN1\n",
      "[04:06:17] SMILES Parse Error: check for mistakes around position 7:\n",
      "[04:06:17] CC1C2C(CC(=O)C1=NC=CN1\n",
      "[04:06:17] ~~~~~~^\n",
      "[04:06:17] SMILES Parse Error: Failed parsing SMILES 'CC1C2C(CC(=O)C1=NC=CN1' for input: 'CC1C2C(CC(=O)C1=NC=CN1'\n",
      "[04:06:17] SMILES Parse Error: unclosed ring for input: 'O=CC1C2CCC(O)(CO)C=CNC1=[NH+]1'\n",
      "[04:06:17] SMILES Parse Error: unclosed ring for input: 'CCC1(C)C2C3NC12C=CC3(O)C2C14'\n",
      "[04:06:17] SMILES Parse Error: extra open parentheses while parsing: CC1(COC(=N)N(C)C(C)=O\n",
      "[04:06:17] SMILES Parse Error: check for mistakes around position 4:\n",
      "[04:06:17] CC1(COC(=N)N(C)C(C)=O\n",
      "[04:06:17] ~~~^\n",
      "[04:06:17] SMILES Parse Error: Failed parsing SMILES 'CC1(COC(=N)N(C)C(C)=O' for input: 'CC1(COC(=N)N(C)C(C)=O'\n",
      "[04:06:17] SMILES Parse Error: extra open parentheses while parsing: OC1(CC1C([O-])=O\n",
      "[04:06:17] SMILES Parse Error: check for mistakes around position 4:\n",
      "[04:06:17] OC1(CC1C([O-])=O\n",
      "[04:06:17] ~~~^\n",
      "[04:06:17] SMILES Parse Error: Failed parsing SMILES 'OC1(CC1C([O-])=O' for input: 'OC1(CC1C([O-])=O'\n",
      "[04:06:17] SMILES Parse Error: unclosed ring for input: 'C1CC(C1)C1CC21'\n",
      "[04:06:17] SMILES Parse Error: ring closure 2 duplicates bond between atom 1 and atom 9 for input: 'OC12CN=C3OCOC3N12'\n",
      "[04:06:17] SMILES Parse Error: unclosed ring for input: 'C(NC1=N)C#N'\n",
      "[04:06:17] SMILES Parse Error: unclosed ring for input: 'OC1CCC2(C)OC1C23'\n",
      "[04:06:18] SMILES Parse Error: unclosed ring for input: 'CC1C2OCC3C1C3CC22'\n",
      "[04:06:18] SMILES Parse Error: unclosed ring for input: 'CC1OC2C(OC13)C24'\n",
      "[04:06:18] SMILES Parse Error: extra close parentheses while parsing: CC1(CO1)C#N)C#C\n",
      "[04:06:18] SMILES Parse Error: check for mistakes around position 12:\n",
      "[04:06:18] CC1(CO1)C#N)C#C\n",
      "[04:06:18] ~~~~~~~~~~~^\n",
      "[04:06:18] SMILES Parse Error: Failed parsing SMILES 'CC1(CO1)C#N)C#C' for input: 'CC1(CO1)C#N)C#C'\n",
      "[04:06:18] SMILES Parse Error: unclosed ring for input: 'CC12C(O)N1C2C3NC3C12'\n",
      "[04:06:18] SMILES Parse Error: unclosed ring for input: 'CC12CCC(C(N)=O)C#C'\n",
      "[04:06:18] SMILES Parse Error: unclosed ring for input: 'CC1C(CC#N)C1CO1'\n",
      "[04:06:18] SMILES Parse Error: ring closure 1 duplicates bond between atom 4 and atom 6 for input: 'OC12CC1C1(C)C1CO1'\n",
      "[04:06:18] SMILES Parse Error: unclosed ring for input: 'NCC1(O)C#C'\n",
      "[04:06:18] SMILES Parse Error: unclosed ring for input: 'CC12CC(C1)C23'\n",
      "[04:06:18] SMILES Parse Error: unclosed ring for input: 'CC1NC1C(=O)C2CC1O'\n",
      "[04:06:18] SMILES Parse Error: ring closure 1 duplicates bond between atom 1 and atom 7 for input: 'CC1(CC#CC#N)C1O2'\n",
      "[04:06:18] SMILES Parse Error: unclosed ring for input: 'CC1CC1(O)CCNC1=O'\n",
      "[04:06:18] SMILES Parse Error: unclosed ring for input: 'CC1=CC(=N)C#N'\n",
      "[04:06:18] SMILES Parse Error: unclosed ring for input: 'CC12CC1(O)C=CC2CN12'\n",
      "[04:06:18] SMILES Parse Error: unclosed ring for input: 'CN(C=O)C12'\n",
      "[04:06:18] SMILES Parse Error: unclosed ring for input: 'OC1CC(C)(O)CC(=O)CNCC=O'\n",
      "[04:06:18] SMILES Parse Error: unclosed ring for input: 'CC(OCC(C)=O)C1(C)C'\n",
      "[04:06:18] SMILES Parse Error: unclosed ring for input: 'OC1C2NC1C1CN2CC12'\n",
      "[04:06:18] SMILES Parse Error: unclosed ring for input: 'COC1(C)C#C'\n",
      "[04:06:18] SMILES Parse Error: unclosed ring for input: 'CC12C3CC(O1)C21CCC1'\n",
      "[04:06:18] SMILES Parse Error: unclosed ring for input: 'CC1(C)CCCC23C1'\n",
      "[04:06:18] SMILES Parse Error: unclosed ring for input: 'O=CC1C2CC(C2)C=O'\n",
      "[04:06:18] SMILES Parse Error: unclosed ring for input: 'CC1OC1CC21CC2CCC12'\n",
      "[04:06:18] SMILES Parse Error: extra open parentheses while parsing: CC1(CNC(C#N)C(N)=O\n",
      "[04:06:18] SMILES Parse Error: check for mistakes around position 4:\n",
      "[04:06:18] CC1(CNC(C#N)C(N)=O\n",
      "[04:06:18] ~~~^\n",
      "[04:06:18] SMILES Parse Error: Failed parsing SMILES 'CC1(CNC(C#N)C(N)=O' for input: 'CC1(CNC(C#N)C(N)=O'\n",
      "[04:06:18] SMILES Parse Error: unclosed ring for input: 'NC1CC1OC2C1CC1'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Performance Report ---\n",
      "Total Generated: 100\n",
      "Validity Rate:   49.0%\n",
      "Novelty Rate:    53.1% (of valid molecules)\n",
      "Avg Prediction Error: 0.5174 eV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[04:06:18] SMILES Parse Error: unclosed ring for input: 'CC12OC1C1(CC1)C1(CO1)C#N'\n",
      "[04:06:19] SMILES Parse Error: unclosed ring for input: 'O=CCC1NC1CC21'\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem  # This fixes the NameError\n",
    "\n",
    "# 1. Prepare the training set for the novelty check\n",
    "training_set = set(df['smiles'].tolist())\n",
    "\n",
    "n_to_generate = 100\n",
    "target_ev = 7.0\n",
    "results = []\n",
    "\n",
    "print(f\"Starting batch generation for {target_ev} eV...\")\n",
    "\n",
    "for i in range(n_to_generate):\n",
    "    # Generate the SMILES string\n",
    "    smiles = generate_for_property(target_ev)\n",
    "    \n",
    "    # 1. Check Validity using RDKit\n",
    "    # We remove the stop token '.' so RDKit can read it properly\n",
    "    mol = Chem.MolFromSmiles(smiles.replace('.', ''))\n",
    "    is_valid = mol is not None\n",
    "    \n",
    "    # 2. Check Novelty\n",
    "    # A molecule is novel if it is NOT in the original training CSV\n",
    "    is_novel = smiles not in training_set\n",
    "    \n",
    "    # 3. Predict Property (only if valid)\n",
    "    pred_ev = predict_generated_property(smiles) if is_valid else None\n",
    "    \n",
    "    results.append({\n",
    "        'smiles': smiles,\n",
    "        'valid': is_valid,\n",
    "        'novel': is_novel,\n",
    "        'pred_ev': pred_ev\n",
    "    })\n",
    "\n",
    "# --- CALCULATION ---\n",
    "valid_count = sum(1 for r in results if r['valid'])\n",
    "if valid_count > 0:\n",
    "    novel_count = sum(1 for r in results if r['valid'] and r['novel'])\n",
    "    avg_error = sum(abs(r['pred_ev'] - target_ev) for r in results if r['valid']) / valid_count\n",
    "    \n",
    "    print(f\"\\n--- Final Performance Report ---\")\n",
    "    print(f\"Total Generated: {n_to_generate}\")\n",
    "    print(f\"Validity Rate:   {(valid_count/n_to_generate)*100:.1f}%\")\n",
    "    print(f\"Novelty Rate:    {(novel_count/valid_count)*100:.1f}% (of valid molecules)\")\n",
    "    print(f\"Avg Prediction Error: {avg_error:.4f} eV\")\n",
    "else:\n",
    "    print(\"No valid molecules generated in this batch. Try training for more steps.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "932340db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install py3Dmol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c413534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/3dmoljs_load.v0": "<div id=\"3dmolviewer_17682739448370385\"  style=\"position: relative; width: 400px; height: 400px;\">\n        <p id=\"3dmolwarning_17682739448370385\" style=\"background-color:#ffcccc;color:black\">3Dmol.js failed to load for some reason.  Please check your browser console for error messages.<br></p>\n        </div>\n<script>\n\nvar loadScriptAsync = function(uri){\n  return new Promise((resolve, reject) => {\n    //this is to ignore the existence of requirejs amd\n    var savedexports, savedmodule;\n    if (typeof exports !== 'undefined') savedexports = exports;\n    else exports = {}\n    if (typeof module !== 'undefined') savedmodule = module;\n    else module = {}\n\n    var tag = document.createElement('script');\n    tag.src = uri;\n    tag.async = true;\n    tag.onload = () => {\n        exports = savedexports;\n        module = savedmodule;\n        resolve();\n    };\n  var firstScriptTag = document.getElementsByTagName('script')[0];\n  firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);\n});\n};\n\nif(typeof $3Dmolpromise === 'undefined') {\n$3Dmolpromise = null;\n  $3Dmolpromise = loadScriptAsync('https://cdn.jsdelivr.net/npm/3dmol@2.5.3/build/3Dmol-min.js');\n}\n\nvar viewer_17682739448370385 = null;\nvar warn = document.getElementById(\"3dmolwarning_17682739448370385\");\nif(warn) {\n    warn.parentNode.removeChild(warn);\n}\n$3Dmolpromise.then(function() {\nviewer_17682739448370385 = $3Dmol.createViewer(document.getElementById(\"3dmolviewer_17682739448370385\"),{backgroundColor:\"white\"});\nviewer_17682739448370385.zoomTo();\n\tviewer_17682739448370385.addModel(\"\\n     RDKit          3D\\n\\n 24 25  0  0  0  0  0  0  0  0999 V2000\\n    2.7099    0.3291    0.3981 C   0  0  0  0  0  0  0  0  0  0  0  0\\n    1.8080    0.1957   -0.7793 C   0  0  0  0  0  0  0  0  0  0  0  0\\n    0.4926   -0.4771   -0.5968 C   0  0  0  0  0  0  0  0  0  0  0  0\\n    0.3223   -1.3900    0.5763 C   0  0  0  0  0  0  0  0  0  0  0  0\\n   -0.7195   -0.8418    1.3463 O   0  0  0  0  0  0  0  0  0  0  0  0\\n   -1.8595   -0.9150    0.5688 C   0  0  0  0  0  0  0  0  0  0  0  0\\n   -2.3256    0.3627   -0.0198 C   0  0  0  0  0  0  0  0  0  0  0  0\\n   -1.2856    1.2991   -0.5170 C   0  0  0  0  0  0  0  0  0  0  0  0\\n    0.1248    0.9231   -0.1930 C   0  0  0  0  0  0  0  0  0  0  0  0\\n    1.0999    1.3769   -1.0612 O   0  0  0  0  0  0  0  0  0  0  0  0\\n    3.4035    1.1828    0.1884 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    3.3469   -0.5644    0.4884 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    2.2195    0.5519    1.3524 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    2.3828   -0.1967   -1.6475 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    0.0550   -0.8004   -1.5513 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    1.2377   -1.5579    1.1515 H   0  0  0  0  0  0  0  0  0  0  0  0\\n   -0.0684   -2.3685    0.2098 H   0  0  0  0  0  0  0  0  0  0  0  0\\n   -1.7757   -1.7290   -0.1965 H   0  0  0  0  0  0  0  0  0  0  0  0\\n   -2.6554   -1.3021    1.2591 H   0  0  0  0  0  0  0  0  0  0  0  0\\n   -2.9741    0.1004   -0.8979 H   0  0  0  0  0  0  0  0  0  0  0  0\\n   -3.0366    0.8499    0.7011 H   0  0  0  0  0  0  0  0  0  0  0  0\\n   -1.4643    2.2930   -0.0261 H   0  0  0  0  0  0  0  0  0  0  0  0\\n   -1.3727    1.5185   -1.6127 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    0.3343    1.1596    0.8591 H   0  0  0  0  0  0  0  0  0  0  0  0\\n  1  2  1  0\\n  2  3  1  0\\n  3  4  1  0\\n  4  5  1  0\\n  5  6  1  0\\n  6  7  1  0\\n  7  8  1  0\\n  8  9  1  0\\n  9 10  1  0\\n 10  2  1  0\\n  9  3  1  0\\n  1 11  1  0\\n  1 12  1  0\\n  1 13  1  0\\n  2 14  1  0\\n  3 15  1  0\\n  4 16  1  0\\n  4 17  1  0\\n  6 18  1  0\\n  6 19  1  0\\n  7 20  1  0\\n  7 21  1  0\\n  8 22  1  0\\n  8 23  1  0\\n  9 24  1  0\\nM  END\\n\",\"mol\");\n\tviewer_17682739448370385.setStyle({\"stick\": {}, \"sphere\": {\"scale\": 0.3}});\n\tviewer_17682739448370385.zoomTo();\nviewer_17682739448370385.render();\n});\n</script>",
      "text/html": [
       "<div id=\"3dmolviewer_17682739448370385\"  style=\"position: relative; width: 400px; height: 400px;\">\n",
       "        <p id=\"3dmolwarning_17682739448370385\" style=\"background-color:#ffcccc;color:black\">3Dmol.js failed to load for some reason.  Please check your browser console for error messages.<br></p>\n",
       "        </div>\n",
       "<script>\n",
       "\n",
       "var loadScriptAsync = function(uri){\n",
       "  return new Promise((resolve, reject) => {\n",
       "    //this is to ignore the existence of requirejs amd\n",
       "    var savedexports, savedmodule;\n",
       "    if (typeof exports !== 'undefined') savedexports = exports;\n",
       "    else exports = {}\n",
       "    if (typeof module !== 'undefined') savedmodule = module;\n",
       "    else module = {}\n",
       "\n",
       "    var tag = document.createElement('script');\n",
       "    tag.src = uri;\n",
       "    tag.async = true;\n",
       "    tag.onload = () => {\n",
       "        exports = savedexports;\n",
       "        module = savedmodule;\n",
       "        resolve();\n",
       "    };\n",
       "  var firstScriptTag = document.getElementsByTagName('script')[0];\n",
       "  firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);\n",
       "});\n",
       "};\n",
       "\n",
       "if(typeof $3Dmolpromise === 'undefined') {\n",
       "$3Dmolpromise = null;\n",
       "  $3Dmolpromise = loadScriptAsync('https://cdn.jsdelivr.net/npm/3dmol@2.5.3/build/3Dmol-min.js');\n",
       "}\n",
       "\n",
       "var viewer_17682739448370385 = null;\n",
       "var warn = document.getElementById(\"3dmolwarning_17682739448370385\");\n",
       "if(warn) {\n",
       "    warn.parentNode.removeChild(warn);\n",
       "}\n",
       "$3Dmolpromise.then(function() {\n",
       "viewer_17682739448370385 = $3Dmol.createViewer(document.getElementById(\"3dmolviewer_17682739448370385\"),{backgroundColor:\"white\"});\n",
       "viewer_17682739448370385.zoomTo();\n",
       "\tviewer_17682739448370385.addModel(\"\\n     RDKit          3D\\n\\n 24 25  0  0  0  0  0  0  0  0999 V2000\\n    2.7099    0.3291    0.3981 C   0  0  0  0  0  0  0  0  0  0  0  0\\n    1.8080    0.1957   -0.7793 C   0  0  0  0  0  0  0  0  0  0  0  0\\n    0.4926   -0.4771   -0.5968 C   0  0  0  0  0  0  0  0  0  0  0  0\\n    0.3223   -1.3900    0.5763 C   0  0  0  0  0  0  0  0  0  0  0  0\\n   -0.7195   -0.8418    1.3463 O   0  0  0  0  0  0  0  0  0  0  0  0\\n   -1.8595   -0.9150    0.5688 C   0  0  0  0  0  0  0  0  0  0  0  0\\n   -2.3256    0.3627   -0.0198 C   0  0  0  0  0  0  0  0  0  0  0  0\\n   -1.2856    1.2991   -0.5170 C   0  0  0  0  0  0  0  0  0  0  0  0\\n    0.1248    0.9231   -0.1930 C   0  0  0  0  0  0  0  0  0  0  0  0\\n    1.0999    1.3769   -1.0612 O   0  0  0  0  0  0  0  0  0  0  0  0\\n    3.4035    1.1828    0.1884 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    3.3469   -0.5644    0.4884 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    2.2195    0.5519    1.3524 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    2.3828   -0.1967   -1.6475 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    0.0550   -0.8004   -1.5513 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    1.2377   -1.5579    1.1515 H   0  0  0  0  0  0  0  0  0  0  0  0\\n   -0.0684   -2.3685    0.2098 H   0  0  0  0  0  0  0  0  0  0  0  0\\n   -1.7757   -1.7290   -0.1965 H   0  0  0  0  0  0  0  0  0  0  0  0\\n   -2.6554   -1.3021    1.2591 H   0  0  0  0  0  0  0  0  0  0  0  0\\n   -2.9741    0.1004   -0.8979 H   0  0  0  0  0  0  0  0  0  0  0  0\\n   -3.0366    0.8499    0.7011 H   0  0  0  0  0  0  0  0  0  0  0  0\\n   -1.4643    2.2930   -0.0261 H   0  0  0  0  0  0  0  0  0  0  0  0\\n   -1.3727    1.5185   -1.6127 H   0  0  0  0  0  0  0  0  0  0  0  0\\n    0.3343    1.1596    0.8591 H   0  0  0  0  0  0  0  0  0  0  0  0\\n  1  2  1  0\\n  2  3  1  0\\n  3  4  1  0\\n  4  5  1  0\\n  5  6  1  0\\n  6  7  1  0\\n  7  8  1  0\\n  8  9  1  0\\n  9 10  1  0\\n 10  2  1  0\\n  9  3  1  0\\n  1 11  1  0\\n  1 12  1  0\\n  1 13  1  0\\n  2 14  1  0\\n  3 15  1  0\\n  4 16  1  0\\n  4 17  1  0\\n  6 18  1  0\\n  6 19  1  0\\n  7 20  1  0\\n  7 21  1  0\\n  8 22  1  0\\n  8 23  1  0\\n  9 24  1  0\\nM  END\\n\",\"mol\");\n",
       "\tviewer_17682739448370385.setStyle({\"stick\": {}, \"sphere\": {\"scale\": 0.3}});\n",
       "\tviewer_17682739448370385.zoomTo();\n",
       "viewer_17682739448370385.render();\n",
       "});\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rdkit.Chem import AllChem\n",
    "import py3Dmol\n",
    "\n",
    "def visualize_3d(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    mol = Chem.AddHs(mol) # 3D needs hydrogens\n",
    "    AllChem.EmbedMolecule(mol, AllChem.ETKDG()) # Generate 3D coordinates\n",
    "    \n",
    "    # Convert RDKit mol to block for py3Dmol\n",
    "    mblock = Chem.MolToMolBlock(mol)\n",
    "    view = py3Dmol.view(width=400, height=400)\n",
    "    view.addModel(mblock, 'mol')\n",
    "    view.setStyle({'stick': {}, 'sphere': {'scale': 0.3}})\n",
    "    view.zoomTo()\n",
    "    return view.show()\n",
    "\n",
    "# Test it with your discovery: CC1C2COCCCC2O1\n",
    "visualize_3d(\"CC1C2COCCCC2O1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e03f4805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights saved successfully from Task 3.\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.parameters(), 'generator_weights.pt')\n",
    "print(\"Weights saved successfully from Task 3.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70ef958",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
